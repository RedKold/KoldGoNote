## 向量数据库产品测试报告

报告人：朱晗
指导老师：谢文婷

### 1. 任务需求分析

在实习期间，我主要的任务是探索向量数据库的相关知识，并基于所学，为Anime Story Music Video (ASMV) 制作开发一个辅助工具。此工具旨在通过语义相似检索，帮助视频剪辑师快速找到合适的台词。该任务的核心需求包括：

* **台词检索的高效性与准确性**：要求工具能在多部电影字幕文件中，快速检索出与用户输入的语义最相似的台词。
* **易于使用的图形用户界面（GUI）**：工具需要具有用户友好的界面，允许用户选择单字幕文件或文件夹，并提供检索显示选项。
* **适应多种需求的检索功能**：支持单电影和多电影混剪的多样需求，能按相似度顺序显示检索结果。

### **2. 相关领域研究**

本项目涉及的相关领域主要包括向量检索技术和机器学习的基础知识：

#### 2.1 向量检索技术

* **向量嵌入**：向量嵌入是将文本数据转换为数值向量的过程，以便在数据库中进行高效查询。常用方法包括基于词袋模型（BoW）、TF-IDF、Word2Vec、BERT等模型。在我的实习过程中，我特别关注了Transformer模型生成向量嵌入的应用，这也是当前最前沿的研究方向之一。
* **向量索引和查询**：向量索引是一种用来快速检索相似向量的方法，例如FAISS和Annoy等向量索引库能够在高维数据中快速找到相似项。向量查询则是利用距离度量（如余弦相似度）来查找相似的向量。

#### 2.2 机器学习基础

* **经典机器学习模型**：我学习了分类算法、决策树、神经网络和支持向量机等基本概念。这些算法为理解深度学习和向量嵌入提供了基础。
* **深度学习与神经网络**：特别是通过阅读《GPT图解》(黄佳，异步图书)和《机器学习》(周志华，清华大学出版社)这两本书，我对深度学习模型的结构和训练过程有了更深入的了解，包括卷积神经网络（CNN）和递归神经网络（RNN）的应用。

### **3. 研究方法及实现技术**

本次实习项目的开发实现可以分为以下几个步骤：

#### 3.1 数据处理与向量化

* **数据预处理**：对输入的.srt字幕文件进行解析，提取时间轴信息和台词文本。数据清洗处理包括去除噪声字符、停用词和标点符号等。
* **向量嵌入生成**：利用Transformer模型将清洗后的文本数据嵌入为数值向量。选用的是基于PyTorch的Transformer模型，它能够捕捉语句的上下文信息，生成语义相似的高质量向量表示。

#### 3.2 开发工具与技术栈

* **PyQt5 GUI 开发**：基于Python的PyQt5框架开发用户界面，使得用户能够通过简单的点击操作来选择字幕文件或文件夹，并查看检索结果。
* **数据库与检索**：在实现过程中，使用FAISS（Facebook AI Similarity Search）库构建向量索引，能够快速高效地进行语义相似检索。

#### 3.3 实验与测试

* **模型训练与评估**：在机器学习基础部分，我通过训练MNIST手写数字识别模型，积累了神经网络的开发经验。在实践过程中，编写了Python代码，验证了kNN、决策树和神经网络模型的效果，并通过混淆矩阵和错误率曲线等方式优化模型。在此之中体会机器学习的基本流程，为后续开发奠定了良好的基础
* **Seq2Seq 与 Attention模型的学习与实现**：学习了经典的Seq2Seq模型和Attention机制的实现过程，并尝试基于此开发一个简单的翻译任务模型，以理解Transformer在自然语言处理中的强大能力。

### **4. 关键成果**

此次实习项目的主要成果可以分为理论学习成果和实际开发成果两部分：

#### 4.1 理论学习成果

* **机器学习与深度学习的深入理解**：掌握了分类算法、神经网络、Transformer等模型的基本原理和实现方式，尤其是在向量嵌入方面有了深入的理解。
* **向量数据库的构建与优化方法**：学习了如何高效构建和优化向量数据库，以支持海量数据的快速相似性查询。

#### 4.2 实际开发成果

* **SrtHelper工具的成功开发**：这是我实习期间开发的一个用于ASMV制作的辅助工具。它可以通过用户选择的.srt文件生成向量数据库，并在其中进行高效的语义相似检索，按相似度顺序显示电影片名、相似度、时间轴和台词信息。
* **丰富的用户功能与体验设计**：通过GUI界面的直观设计和功能丰富的辅助选项，为ASMV制作者提供了良好的支持。有着较大的开发潜力，得到了领导和老师的认可。

### **5. 结论与未来展望**

通过此次实习，我在向量检索、机器学习和应用开发方面积累了大量的经验。未来的工作将聚焦于以下几个方向：

* **功能扩展与优化**：在现有工具基础上增加更多的检索维度，如音频检索、视频片段自动生成等功能，以增强工具的实用性和效率。
* **深度学习模型的优化与应用**：进一步研究和优化用于向量嵌入的深度学习模型，以提高检索的准确率和速度。

在未来的研究和开发中，我希望能将此次实习中获得的经验应用到更多的实际问题解决中，精进自己的学习能力，为走上以后的工作岗位做好万足准备。

## 6. 参考文献

1. 周志华. *机器学习*. 清华大学出版社, 2016.
2. 黄佳. *图解GPT: 深度学习与自然语言处理入门*. 人民邮电出版社, 2023.
3. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is All You Need. *Advances in Neural Information Processing Systems*, 30, 5998-6008.
4. July. (2023). *深入理解向量检索：原理、实现与优化*. CSDN. Retrieved from [https://blog.csdn.net/v\_JULY\_v/article/details/127411638](https://blog.csdn.net/v_JULY_v/article/details/127411638)
5. MyScale. (2024). *关于向量索引的所有内容*. Retrieved from [https://myscale.com/blog/zh/everything-about-vector-indexing/](https://myscale.com/blog/zh/everything-about-vector-indexing/)## 附件

## 7. 附件

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from matplotlib import pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
datasets=fetch_openml("mnist_784",version=1,as_frame=False)

print(datasets.keys())

#img
X=datasets['data']
#labels
y=datasets['target']

# 将数据转换为浮点数
X = X.astype(np.float32)  # 转换为 float32 类型以便与 PyTorch 兼容

# 将标签转换为整数
y = y.astype(np.int64)  # 转换为 int64 类型以便与 PyTorch 兼容
#例举一些图显示出来

class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        #三个线性层
        self.fc1=nn.Linear(28*28,64)
        self.fc2=nn.Linear(64,64)
        self.fc3=nn.Linear(64,64)
        self.fc4=nn.Linear(64,10)
    # parameter x：传入图片
    # 定义向前传播代码
    def forward(self,x):
        x=F.relu(self.fc1(x))
        x=F.relu(self.fc2(x))
        x=F.relu(self.fc3(x))
        x=F.log_softmax(self.fc4(x),dim=-1)
        return x

#划分训练集和测试集
X_train=torch.from_numpy(X[:3000])
y_train=torch.from_numpy(y[:3000])
X_test=torch.from_numpy(X[3000:])
y_test=torch.from_numpy(y[3000:])

#set the model
net=Net()

#create loss list
losses = []

def Training(X_train, y_train, epochs):
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001)  # 降低学习率
    batch_size = 32  # 设置批次大小

    for epoch in range(epochs):
        for i in range(0, len(X_train), batch_size):
            net.zero_grad()

            # 获取当前批次的数据
            X_batch = X_train[i:i + batch_size].view(-1, 28 * 28)
            y_batch = y_train[i:i + batch_size]

            output = net(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()

            # 每次迭代都记录损失
            losses.append(loss.item())

#super Parameters
import random
epochs=5

if __name__ == '__main__':
    Training(X_train, y_train, epochs)

    # 使用测试集进行预测
    y_pred = []
    for i in range(len(X_test)):
        pred = net(X_test[i].view(-1, 28*28))
        y_pred.append(torch.argmax(pred, dim=1).item())

  

    # 生成混淆矩阵
    cm = confusion_matrix(y_test, y_pred)

    # 可视化混淆矩阵
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.show()

    # 绘制损失曲线
    plt.title("Error curve")
    plt.plot(range(len(losses)), losses)
    plt.show()

```

下面介绍SrtHelper的主要部分代码(from main.py)

```python
#main.py
from PyQt5.QtCore import Qt
from PyQt5.QtWidgets import QWidget, QApplication, QVBoxLayout, QLabel, QPushButton, QMainWindow
import sys
import setVectorBase
from Ui_qwidget import Ui_SrtHelper
from PyQt5.QtWidgets import QFileDialog
import os
import storeVectorBase

os.chdir("E:\\Codinglife\\Python_project\\SRT-learner")


#主窗口类，继承自qwideget
class MyWidget(QWidget, Ui_SrtHelper):
    #定义几个模式的常数
    #Fl:File, Dr:Directory
    Models=['Fl','Dr']
    #初始值
    model=Models[0]
    def __init__(self, parent=None):
        super(MyWidget, self).__init__(parent)
        self.setupUi(self)
        self.inputPush.clicked.connect(self.inputPush_clicked)  # 将点击事件绑定到类方法
        #init the default srt path
        self.FilenameLabel.setText("E:/Codinglife/Python_project/SRT-learner/srt/Frozen_chs.srt")
  
        # 初始化 SubtitleViewer 为 None
        self.viewer = None
        # 将选择字幕文件按钮点击信号与对应处理函数连接
        self.selectSrtButton.clicked.connect(self.openFileDialog)
        self.selectDirecButton.clicked.connect(self.openDirecDialog)

        #隐藏工具人文件名label
        self.FilenameLabel.setVisible(False)
  

    def openFileDialog(self):
        options = QFileDialog.Options()
        options |= QFileDialog.ReadOnly  # 只读模式（可选）
  
        # 第一个参数是父组件，第二个参数是对话框标题，第三个参数是默认路径
        #过滤出符合srt条件的文件
        file_path, _ = QFileDialog.getOpenFileName(None, "选择.srt 文件", "", "字幕文件 (*.srt)", options=options)
  
        if file_path:
            self.FilenameLabel.setText(file_path)

    def openDirecDialog(self):
            # 获取前 k 条最相似的台词和时间轴
        k = self.amtspinBox.value()
        query = self.inputLineEdit.text()

        # 调试
        print(f"当前查找请求为:{query}")

        # 选择一个目录
        dir_path = QFileDialog.getExistingDirectory(self, "选择包含数据库的目录")
  
        if not dir_path:
            print("未选择目录")
            return
  
        # 遍历目录中的所有 .pkl 文件
        db_files = [f for f in os.listdir(dir_path) if f.endswith('_db.pkl')]
  
        if not db_files:
            print("未找到数据库文件")
            return
  
        # 存储所有数据库的检索结果
        all_top_k_lines = []
        all_top_k_timestamps = []
        all_top_k_similarities = []
        all_top_k_filmnames=[]

        # 对每个数据库文件进行检索
        for db_filename in db_files:
            full_path = os.path.join(dir_path, db_filename)
            print(f"正在加载数据库 {full_path}")

            # 加载数据库（这里假设有一个 load_db 函数）
            setVectorBase.load_embeddings(full_path)

            # 查找最相似的台词
            top_k_lines, top_k_timestamps, top_k_similarities,top_k_filmname = setVectorBase.find_most_similar(query, k,db_file=full_path)

            # 将结果存储到总列表中
            # (Python tips) extend 会把元素内容展开加到后面，append会直接硬加进来
            all_top_k_lines.extend(top_k_lines)
            all_top_k_timestamps.extend(top_k_timestamps)
            all_top_k_similarities.extend(top_k_similarities)
            all_top_k_filmnames.extend(top_k_filmname)

            #排序处理
            # 合并为一个包含所有数据的元组列表
            all_results = list(zip(all_top_k_lines, all_top_k_timestamps, all_top_k_similarities, all_top_k_filmnames))

            # 按相似度从高到低排序
            all_results.sort(key=lambda x: x[2], reverse=True)

            #print(f"all_result is: {list(all_results)}")
            # 将排序后的结果重新解压
            all_top_k_lines, all_top_k_timestamps, all_top_k_similarities, all_top_k_filmnames = zip(*all_results)#'*'是解包运算符
   
            all_top_k_lines=list(all_top_k_lines)
            all_top_k_timestamps=list(all_top_k_timestamps)
            all_top_k_similarities=list(all_top_k_similarities)
            all_top_k_filmnames=list(all_top_k_filmnames)

        # 显示所有数据库的综合结果



        self.viewer = SubtitleViewer(all_top_k_lines, all_top_k_timestamps, all_top_k_similarities,all_top_k_filmnames,k)
        self.viewer.show()
  

    def inputPush_clicked(self):
        # 获取前 k 条最相似的台词和时间轴
        k=self.amtspinBox.value()
        query=self.inputLineEdit.text()

        #调试
        print(f"当前查找请求为:{query}")

        filename=self.FilenameLabel.text()

        #print(f"inputPush按钮要打开的是{filename}")

        db_filename=f"{filename}_db.pkl"
        if not os.path.exists(db_filename):
            print("不存在现有的数据库，创建新数据库中")
            storeVectorBase.generate_and_save_embeddings(filename,db_file=db_filename)
        else:
            print("已存在相关数据库，为你检索中")
    
        top_k_lines, top_k_timestamps, top_k_similarities = setVectorBase.find_most_similar(query,k,db_file=db_filename)

        # 创建并显示 SubtitleViewer
        self.viewer = SubtitleViewer(top_k_lines, top_k_timestamps, top_k_similarities,k)
        self.viewer.show()  # 使用 show() 方法显示窗口


class SubtitleViewer(QWidget):
    def __init__(self, lines, timestamps, similarities,filmname,k=5):
        super().__init__()

        self.setWindowTitle("最相似台词查询结果")
        self.setGeometry(100, 100, 500, 300)
        layout = QVBoxLayout()

        #print(filmname)
        # 显示前 k 条最相似的台词和时间轴
        for i in range(k):
            if(len(filmname)>=1):
                label = QLabel(f"{i+1}. 电影: {filmname[i]}\n相似度: {similarities[i]:.4f}\n时间轴: {timestamps[i]}\n台词: {lines[i]}\n")
            else:
                label = QLabel(f"{i+1}.相似度: {similarities[i]:.4f}\n时间轴: {timestamps[i]}\n台词: {lines[i]}\n")
            layout.addWidget(label)

        self.setLayout(layout)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    myWin = MyWidget()
    myWin.show()
    sys.exit(app.exec_())

```

介绍读取.srt格式文件的代码(ReadSrt.py)

```python
import pickle
import os
from sentence_transformers import SentenceTransformer

def generate_and_save_embeddings(srt_file, model_name='paraphrase-multilingual-MiniLM-L12-v2', db_file='subtitle_db.pkl'):
    # 初始化模型
    model = SentenceTransformer(model_name)

    # 读取 SRT 文件并处理
    import pysrt
    subs = pysrt.open(srt_file, encoding='utf-8')
    lines = [sub.text.replace('\n', ' ') for sub in subs]
    timestamps = [f"{sub.start} --> {sub.end}" for sub in subs]

    # 生成嵌入向量
    embeddings = model.encode(lines, convert_to_tensor=True)

    # 存储数据到本地文件
    with open(db_file, 'wb') as db:
        pickle.dump({
            'lines': lines,
            'timestamps': timestamps,
            'embeddings': embeddings
        }, db)
    print(f"数据已保存到 {db_file}")

if __name__ == "__main__":
    # 生成并保存字幕数据库
    srt_file = 'srt/Frozen_chs.srt'  # 替换为你的 SRT 文件路径
    generate_and_save_embeddings(srt_file,db_file=f'{srt_file}_db.pkl')import pysrt
import os

# 切换到指定工作目录
current_dir = os.getcwd()
print(f"Current working directory: {current_dir}")
os.chdir("E:\\Codinglife\\Python_project\\SRT-learner")

# 读取 SRT 文件并建立台词与时间轴的对照表
def read_srt(file_path):
    subs = pysrt.open(file_path)
    # 存储台词和时间轴信息的字典
    subtitle_dict = {}
  
    for sub in subs:
        start_time = sub.start.to_time()  # 获取开始时间
        end_time = sub.end.to_time()      # 获取结束时间
        text = sub.text.replace('\n', ' ')  # 将多行台词合并为一行
        time_range = f"{start_time} --> {end_time}"
        subtitle_dict[time_range] = text

    return subtitle_dict

# 保存对照表到文本文件
def save_to_file(subtitle_dict, output_file):
    with open(output_file, 'w', encoding='utf-8') as file:
        for time_range, text in subtitle_dict.items():
            file.write(f"{time_range}:\n{text}\n")

# 示例：读取并保存
if __name__ == "__main__":
    file_path = 'srt\\Frozen_chs.srt'  # 替换为你的 SRT 文件路径
    output_file = 'output_str.txt'     # 替换为输出文件路径
    subtitle_dict = read_srt(file_path)
    save_to_file(subtitle_dict, output_file)

    print(f"台词和时间轴对照表已保存到 {output_file}")
```

向量嵌入部分代码(from storeVectorBase.py)

```python
import pickle
import os
from sentence_transformers import SentenceTransformer

def generate_and_save_embeddings(srt_file, model_name='paraphrase-multilingual-MiniLM-L12-v2', db_file='subtitle_db.pkl'):
    # 初始化模型
    model = SentenceTransformer(model_name)

    # 读取 SRT 文件并处理
    import pysrt
    subs = pysrt.open(srt_file, encoding='utf-8')
    lines = [sub.text.replace('\n', ' ') for sub in subs]
    timestamps = [f"{sub.start} --> {sub.end}" for sub in subs]

    # 生成嵌入向量
    embeddings = model.encode(lines, convert_to_tensor=True)

    # 存储数据到本地文件
    with open(db_file, 'wb') as db:
        pickle.dump({
            'lines': lines,
            'timestamps': timestamps,
            'embeddings': embeddings
        }, db)
    print(f"数据已保存到 {db_file}")

if __name__ == "__main__":
    # 生成并保存字幕数据库
    srt_file = 'srt/Frozen_chs.srt'  # 替换为你的 SRT 文件路径
    generate_and_save_embeddings(srt_file,db_file=f'{srt_file}_db.pkl')
```

向量库读取和查询核心代码(from setVecBase.py)

```python
import pickle
import torch
from sentence_transformers import SentenceTransformer, util
import os

def load_embeddings(db_file='subtitle_db.pkl'):
    with open(db_file, 'rb') as db:
        data = pickle.load(db)
    return data['lines'], data['timestamps'], data['embeddings']

def find_most_similar(query,k,model_name='paraphrase-multilingual-MiniLM-L12-v2', db_file='subtitle_db.pkl'):
    # 加载本地保存的嵌入数据
    lines, timestamps, embeddings = load_embeddings(db_file)

    # 加载模型进行查询
    model = SentenceTransformer(model_name)
    query_embedding = model.encode(query, convert_to_tensor=True)

    # 计算余弦相似度
    cosine_sim = util.cos_sim(query_embedding, embeddings)

    # 找到前 k 条最相似的台词
    top_k_indices = torch.topk(cosine_sim, k).indices
    top_k_indices=torch.squeeze(top_k_indices)
    #print(top_k_indices)
    top_k_indices=top_k_indices.tolist()

    # 返回相应的台词、时间轴和相似度
    top_k_lines = list([lines[i] for i in top_k_indices])
    top_k_timestamps = [timestamps[i] for i in top_k_indices]
    top_k_similarities = [cosine_sim[0][i].item() for i in top_k_indices]
    filmname=[os.path.basename(db_file)[:-15]]*k
    return top_k_lines, top_k_timestamps, top_k_similarities,filmname
```
